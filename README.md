### VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles

This repository contains code and dataset for the EMNLP 2020 paper VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles. 

# About the corpus
Overall, there are 184,920 samples in the dataset, which is split into a training set of 180,000 samples, a validation set of 2,460 samples, and a test set of 2,460 samples.


# How to get VMSMO corpus?
Signed the following copyright announcement with your name and organization. Then complete the form online(https://forms.gle/2cXTasjx6Pr9n1jeA) and mail to xy-chen#pku.edu.cn ('#'->'@'), we will send you the corpus by e-mail when approved.

# Copyright
The original copyright belongs to the source owner.

The copyright of annotation belongs to our group, and they are free to the public.

The dataset is only for research purposes. Without permission, it may not be used for any commercial purposes and distributed to others.

# Citation
We appreciate your citation if you find our dataset is beneficial.

```
@inproceedings{Li020vmsmo,
  title={Learning to Generate Multimodal Summary for Video-based News Articles},
  author={Mingzhe Li, Xiuying Chen, Shen Gao, Zhangming Chan, Dongyan Zhao and Rui Yan},
  booktitle = {EMNLP},
  year = {2020}
}
```
